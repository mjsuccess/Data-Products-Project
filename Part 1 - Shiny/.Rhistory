iris_forest <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris)
print(iris_forest)
iris_ctree <- ctree(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris)
ctree_pred = predict(iris_ctree,newdata=iris[,-5])
table(iris$Species,ctree_pred)
plot(iris_forest)
pred_species = vector(length = length(iris$Species))
pred_species = vector(length = length(iris$Species))
for(i in length(iris$Species))
{
tempForest = randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris[-i,])
pred_species[i] = predict(tempForest,newdata=iris[i,-5])
}
pred_species
tempForest
for(i in 1:length(iris$Species))
{
tempForest = randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data=iris[-i,])
pred_species[i] = predict(tempForest,newdata=iris[i,-5])
}
hist(pred_species)
table(iris$Species,pred_species)
pred_species = factor(pred_species,labels = c("setosa","versicolor","virginica"))
table(iris$Species,pred_species)
?predict
predict(iris_ctree,newdata=iris,interval='prediction')
predict(iris_ctree,newdata=iris,type='response')
predict(iris_ctree,newdata=iris,"prob")
iris_forest$predicted
predict(iris_forest, iris[,-5], "prob")
a = seq(1:6)
mean(a)
var(a)
library(MASS)
?shuttle
str(shuttle$use)
shuttle$use.binary <- as.integer(shuttle$use == "auto")
names(shuttle)
str(shuttle$use.binary)
fit <- glm(use.binary ~ wind - 1, data = shuttle, family = binomial)
summary(fit)$coef
exp(coef(fit))[1]/exp(coef(fit))[2]
coef(fit)
exp(coef(fit))
exp(coef(fit)[1])
exp(coef(fit))[1]
exp(coef(fit)[1])/exp(coef(fit)[2])
unname(exp(coef(fit))[1]/exp(coef(fit))[2])
str(shuttle$use)
library(MASS)
shuttle$use.binary <- as.integer(shuttle$use == "auto")
fit <- glm(use.binary ~ wind + magn - 1, data = shuttle, family = binomial)
summary(fit)$coef
coef(fit)
exp(coef(fit))
exp(coef(fit)[1])/exp(coef(fit)[2])
unname(exp(coef(fit)[1])/exp(coef(fit)[2]))
library(MASS)
shuttle$use.binary<- as.integer(shuttle$use=="auto")
fit<- glm(use.binary~wind-1,data=shuttle,family=binomial)
summary(fit)$coef
fit1<- glm(1-use.binary~wind-1,data=shuttle,family=binomial)
summary(fit1)$coef
fit<- glm(count~factor(spray)-1,family="poisson",data=InsectSprays)
summary(fit)
unname(exp(coef(fit)[1])/exp(coef(fit)[2]))
length(InsectSprays$spray)
summary(mtcars)
summary(mtcars)$carb
names(summary(mtcars))
str(summary(mtcars))
a = summary(mtcars)
a[1]
str(a[1])
a[1,]
str(a[2])
str(a[22])
str(a[66])
a[,1]
a[1,1]
a[1:3,1]
a[1:3,1:3]
a[1:6,1:4]
a
mtcars$vs = factor(mtcars$vs)
summary(mtcars)
?mtcars
dim(mtcars)
str(mtcars)
data(mtcars)
dim(mtcars)
str(mtcars)
lm(mpg~.)
data(mtcars)
lm(mpg~.)
Sys.getenv()
Sys.setenv(mtcars)
Sys.setenv(data=mtcars)
Sys.setenv(data="mtcars")
Sys.getenv()
vs
?attach
attach(mtcars)
vs
str(mtcars)
factor(vs)
factor(vs);factor(am)
cyl=factor(cyl);vs=factor(vs);am=factor(am);gear=factor(gear);carb=factor(carb)
summary(mtcars)
?factor
?mtcars
fit=lm(mpg~am)
summary(fit)
fit$residuals
hist(fit$residuals)
?hist
hist(fit$residuals, breaks=3)
?hist
hist(fit$residuals, breaks=5)
?hist
?qq
?qqplot
qqnorm(fit$residuals)
qqline()
qqline(fit$residuals)
summary(fit)
a=summary(fit)
a$adj.r.squared
a$coefficients
library(caret); library(kernlab); data(spam)
install.packages("caret")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
set.seed(1234)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
set.seed(1234)
inTrain2 <- createDataPartition(y=spam$make,p=0.75, list=F)
inTrain
set.seed(1234)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
set.seed(1234)
inTrain2 <- createDataPartition(y=spam$type,p=0.75, list=F)
set.seed(1234)
inTrain3 <- createDataPartition(y=spam$make,p=0.75, list=F)
class(inTrain)
all.equal(inTrain,inTrain2)
all.equal(inTrain,inTrain3)
colnames(inTrain)
inTrain[,2] <- inTrain2$Resample1
inTrain[,2] <- inTrain2[,1]
dim(inTrain)
inTrain[2,] <- inTrain2[1,]
dim(inTrain)
t(inTrain)
all.equal(inTrain,inTrain3)
all.equal(inTrain,inTrain2)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
set.seed(1234)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
inTrain2 <- createDataPartition(y=spam,p=0.75, list=F)
training <- spam[inTrain3]
args(train)
install.packages("caret")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=F)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main = "",xlab = "ave. capital run length")
install.packages("caret")
preObj <- preProcess(training[,-58])$capitalAve
preObj <- preProcess(training[,-58],method = c("center","scale"))
trainCapAves <- predict(preObj,training[,-58])$capitalAve
summary(trainCapAves)
sd(trainCapAves)
hist(trainCapAves)
hist(training$capitalAve,main = "",xlab = "ave. capital run length")
hist(trainCapAves)
hist(training$capitalAve,main = "",xlab = "ave. capital run length")
preObj <- preProcess(training[,-58],method = c("center","scale"))
trainCapAves <- predict(preObj,training[,-58])$capitalAve
summary(trainCapAves)
sd(trainCapAves)
par(mfrow=c(1,2));hist(trainCapAves)
par(mfrow=c(1,2));hist(training$capitalAve);hist(trainCapAves)
preObj <- preProcess(training[,-58],method = c("BoxCox"))
trainCapAves <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2));hist(trainCapAves);qqnorm(trainCapAves)
install.packages("e1071")
library(e1071)
preObj <- preProcess(training[,-58],method = c("BoxCox"))
trainCapAves <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2));hist(trainCapAves);qqnorm(trainCapAves)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob = 0.05)==1
selectNA
training$capAve[selectNA]<-NA
summary(training$capAve)
summary(training$capitalAve)
preObj <- preProcess(training[,-58],method = "knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
install.packages("RANN");library(RANN)
set.seed(13343)
#make some NA's
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob = 0.05)==1
training$capAve[selectNA]<-NA
summary(training$capAve)
summary(training$capitalAve)
preObj <- preProcess(training[,-58],method = "knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
summary(capAve)
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
install.packages("quantmod")
library(quantmod)
from.dat <- as.Date("01/01/08",format="%m/%d/%y")
to.dat <- as.Date("12/31/13",format="%m/%d/%y")
getSymbols("GOOG",src="google",from=from.dat,to=to.dat)
rm(list=ls())
library(quantmod)
from.dat <- as.Date("01/01/08",format="%m/%d/%y")
to.dat <- as.Date("12/31/13",format="%m/%d/%y")
getSymbols("GOOG",src="google",from=from.dat,to=to.dat,"getSymbols.warning4.0"=FALSE)
head(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
rm(list=ls())
install.packages("ElemStatLearn")
library(ElemStatLearn)
library(ElemStatLearn)
data(vowel.train)
rm(list=ls())
pml_train <- read.csv("C:/Users/J Miller/Desktop/Data Science Course/Practical Machine Learning/Assignment/pml-training.csv")
Testing <- read.csv("C:/Users/J Miller/Desktop/Data Science Course/Practical Machine Learning/Assignment/pml-testing.csv")
#install.packages("caret")
library(caret); library(rpart)
# Delete variables are irrelevant to our current project: user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window (columns 1 to 7).
pml_train <- pml_train[,-c(1:7)]
Testing <- Testing[,-c(1:7)]
# Delete columns with all missing values
pml_train <- pml_train[,colSums(is.na(pml_train)) == 0]
keepNZV <- names(Testing) %in% names(pml_train)
Testing <- Testing[,keepNZV]
# partition the data so that 75% of the training dataset into training and the remaining 25% to testing
part <- createDataPartition(y=pml_train$classe, p=0.75, list=FALSE)
Training <- pml_train[part, ]
Validation <- pml_train[-part, ]
model1 <- train(classe ~ .,data=Training,method = "rpart",cp=0.002,maxdepth=8)
rm(list=ls())
pml_train <- read.csv("C:/Users/J Miller/Desktop/Data Science Course/Practical Machine Learning/Assignment/pml-training.csv")
Testing <- read.csv("C:/Users/J Miller/Desktop/Data Science Course/Practical Machine Learning/Assignment/pml-testing.csv")
#install.packages("caret")
library(caret); library(rpart); library(randomForest); library(rattle);
# Delete variables are irrelevant to our current project: user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window (columns 1 to 7).
pml_train2 <- pml_train[,-c(1:7)]
Testing <- Testing[,-c(1:7)]
# Delete columns with all missing values
pml_train2 <- pml_train2[,colMeans(is.na(pml_train2) | pml_train2=="") < .66]
keepNZV <- names(Testing) %in% names(pml_train2)
Testing <- Testing[,keepNZV]
# partition the data so that 75% of the training dataset into training and the remaining 25% to testing
part <- createDataPartition(y=pml_train2$classe, p=0.6, list=FALSE)
Training <- pml_train2[part, ]
Validation <- pml_train2[-part, ]
x <- createDataPartition(y=pml_train2$classe, p=0.05, list=FALSE)
x2 <- pml_train2[x,]
model1 <- train(classe ~ .,data=x2,method = "rpart")
model1 <- rpart(classe ~ ., data=Training, method="class")
prediction1 <- predict(model1, Validation, type = "class")
# Plot the Decision Tree
fancyRpartPlot(model1)
confusionMatrix(prediction1, Validation$classe)
model2 <- rpart(classe ~ ., data=Training, method="rf")
model2 <- randomForest(classe ~ ., data=Training, method="rf")
prediction2 <- predict(model2, Validation, type = "class")
# Test results on Validation data set:
confusionMatrix(prediction2, Validation$classe)
predictfinal <- predict(model2, Testing, type="class")
predictfinal
```{r, echo=FALSE}
rm(list = ls())
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey")
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv")
data
header=T,sep=" ")
header = T,sep=" ")
header = T, sep=" ")
header = TRUE , sep=" ")
header = TRUE)
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE)
data
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE, sep = " ")
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE, sep = ",")
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE, sep = "/")
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE, sep = ".")
data <- read.csv("C:/Users/J Miller/Desktop/Work/Staff survey/nonameco staff survey.csv",header = TRUE, sep = "\t")
colnames(data)
sD <- data[,seq(1,19)]
summary(sD)
summary(sD[,6])
sD <- data[,seq(62,77)]
summary(sD)
install.packages("xgboost")
library(xgboost)
?xgb.importance
colnames(SD)
colnames(sD)
class(colnames(sD))
colnames(sD)==names(sD)
?xgboost
class(sD)
as.matrix(sD)
model <- xgboost(data = as.matrix(sD),label = "")
class(sD[1,1])
sD <- as.numeric(as.matrix(sD))
class(sD[1])
sD <- matrix(sD,nrow = 49)
sD
colnames(sD) <- names(data)[c(62:77)]
sD
class(sD[1,1])
sapply(sD, mode)
sD <- data[,seq(62,77)]
sapply(sD, mode)
sapply(as.matrix(sD), mode)
mode(sD)
mode(sD[1,1])
class(sD[1,1])
sapply(sD, class)
sapply(as.matrix(sD), class)
sapply(sD, as.numeric)
sapply(sD, class)
sapply(as.matrix(sD), class)
sD2 <- sapply(sD, as.numeric)
sapply(sD2, class)
class(sD2)
class(sD)
sD <- sapply(sD, as.numeric)
model <- xgboost(data = as.matrix(sD),label = "")
model <- xgboost(data = sD)
names(sD[,1])
colnames(sD[,1])
class(sD)
sD
colnames(sD)
colnames(sD)[1]
model <- xgboost(data = sD, label = colnames(sD)[1])
args(xgboost)
model <- xgboost(data = sD, label = sD[1,])
length(sD[1,])
length(sD[,1])
model <- xgboost(data = sD, label = sD[,1])
model <- xgboost(data = sD, label = sD[,1],nrounds=30)
model <- xgboost(data = sD, label = sD[,1],nrounds=50)
model <- xgboost(data = sD, label = sD[,1],nrounds=500)
model <- xgboost(data = sD, label = sD[,1],nrounds=50)
model <- xgboost(data = sD, label = sD[,1],nrounds=30)
model <- xgboost(data = sD, label = sD[,1],nrounds=40)
class(model)
?xgb.importance
model <- xgboost(data = sD[,-1], label = sD[,1],nrounds=40)
model <- xgboost(data = sD[,-1], label = sD[,1],nrounds=100)
xgb.importance(feature_names = fn,model = model,data = sD[,-1],label = sD[,1])
fn <- names(sD[,-1])
xgb.importance(feature_names = fn,model = model,data = sD[,-1],label = sD[,1])
debug(xgb.importance(feature_names = fn,model = model,data = sD[,-1],label = sD[,1]))
xgb.importance(feature_names = names(sD),model = model,data = sD[,-1],label = sD[,1])
model <- xgboost(data = sD[,-1], label = sD[,1],nrounds=100)
model <- xgboost(data = sD[,-1], label = sD[,1],nrounds=45)
xgb.importance(feature_names = names(sD),model = model,data = sD[,-1],label = sD[,1])
summary(model)
dim(model)
dim(fn)
fn <- as.vector(names(sD[,-1]))
dim(fn)
fn
dim(names(sD))
names(sD)
sD
names(sD)
colnames(sD)
dim(colnames(sD))
class(colnames(sD))
mode(colnames(sD))
dim(colnames(sD))
as.vector(colnames(sD))
dim(as.vector(colnames(sD)))
class(as.vector(colnames(sD)))
fn <- as.vector(colnames(sD))
summary(fn)
fn2 <- as.matrix(fn)
fn2 <- matrix(fn,nrow = 4)
summary(fn2)
class(fn2)
fn <- vector(colnames(sD))
?vector
is.vector(fn)
length(fn)
fn <- as.vector(colnames(sD)[-1])
length(fn)
xgb.importance(feature_names = fn,model = model,data = sD[,-1],label = sD[,1])
imp <- xgb.importance(feature_names = fn,model = model,data = sD[,-1],label = sD[,1])
imp
class(imp)
imp$Feature
?xgb.importance
fn
imp$Split
imp$Gain
imp$Frequence
imp$RealCover
imp$RealCover%
imp$`RealCover %`
library(foreign)
dataset = read.spss("C:\Users\J Miller\Desktop\Work\Janahanda\2016_10\Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE)
dataset = read.spss("C:/Users/J Miller/Desktop/Work/Janahanda/2016_10/Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE)
?read.spss
dataset = read.spss("C:/Users/J Miller/Desktop/Work/Janahanda/2016_10/Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE, reencode = ="utf-8")
dataset = read.spss("C:/Users/J Miller/Desktop/Work/Janahanda/2016_10/Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE, reencode="utf-8")
dataset = read.spss("C:/Users/J Miller/Desktop/Work/Janahanda/2016_10/Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE, reencode="utf-16")
dataset = read.spss("C:/Users/J Miller/Desktop/Work/Janahanda/2016_10/Janahanda 5 - Sep 2016 - Final data.sav", to.data.frame=TRUE, reencode="utf-8")
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
symbols(galton$child, galton$parent, xlab='child height', col='lightblue',main='Histogram')
symbols(galton$child, circles = galton$parent, xlab='child height', col='lightblue',main='Histogram')
?seq
dat=data.frame(one=c(1:10),two=seq(4,40,by=4))
dat
dat=data.frame(one=c(1:10),two=sample(seq(4,40,by=4),size = 10,replace = F),three=runif(10,min=1,max=20))
dat
symbols(dat$one,dat$two,circles = dat$three)
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
symbols(dat$one,dat$two,circles = dat$three, xlab='child height', col='lightblue',main='Histogram')
lines(c(4, 4), c(0, 30),col="red",lwd=5)
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
?text
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
?symbols
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
?sliderInput
dat=data.frame(one=c(1:10),two=sample(seq(4,40,by=4),size = 10,replace = F),three=runif(10,min=1,max=20))
symbols(dat$one,dat$two,circles = dat$three, ylim = c(0,70), xlab='child height', col='lightblue',main='Histogram')
symbols(3,20,10)
symbols(dat$one,dat$two,circles = dat$three, ylim = c(0,70), xlab='child height', col='lightblue',main='Histogram')
symbols(3,20,10,add = T)
symbols(3,20,10,add = T,fg="red",bg="red")
symbols(3,20,10,add = T,fg="red",bg="bl")
symbols(3,20,10,add = T,fg="red",bg=1)
symbols(3,20,10,add = T,fg="red",bg=1.1)
symbols(3,20,10,add = T,fg="red",bg=1.7)
symbols(3,20,10,add = T,fg="red",bg=2.9)
symbols(3,20,10,add = T,fg="red",bg=2.7)
symbols(3,20,10,add = T,fg="red",bg=3)
symbols(3,20,10,add = T,fg="red",bg=4)
symbols(3,20,10,add = T,fg="red",bg=5)
symbols(3,20,10,add = T,fg="red",bg=6)
symbols(3,20,10,add = T,fg="red",bg=7)
symbols(3,20,10,add = T,fg="red",bg=8)
symbols(3,20,10,add = T,fg="red",bg=11)
symbols(3,20,10,add = T,fg="red",bg=9)
dat[min(dat$one),,]$thre
dat[min(dat$one),,]$three
dat[min(dat$one),,]$one
dat[min(dat$one),,]$two
dat[min(dat$one),,]$one-dat[min(dat$one),,]$three
floor(dat[min(dat$one),,]$one-dat[min(dat$one),,]$three)
ceiling(dat[min(dat$one),,]$one-dat[min(dat$one),,]$three)
ceiling(dat[max(dat$one),,]$one+dat[max(dat$one),,]$three)
floor(dat$one-dat$three)
min(floor(dat$one-dat$three))
max(ceiling(dat$one+dat$three))
ceiling(dat$one+dat$three)
data.frame(dat$one,dat$three,ceiling(dat$one+dat$three))
symbols(8,20,circles = 19)
symbols(8,20,circles = 19,ylim = c(0,40))
symbols(rep(8,times=5),rep(20,times=5),circles = c(1,2,4,8,19),ylim = c(0,40))
symbols(dat$one,dat$two,circles = dat$three, xlim = c(a,b), ylim = c(c,85), xlab='child height', col='lightblue',main='Histogram')
symbols(dat$one,dat$two,circles = dat$three, col='lightblue')
n=ceiling(runif(1,min=7,max=30))
dat=data.frame(one=seq(1,15,by=15/n),
two=sample(seq(4,40,by=40/n),size = 10,replace = F),
three=runif(n,min=1,max=20))
n
seq(1,15,by=15/n)
seq(1,15,by=14/n)
n=ceiling(runif(1,min=7,max=30))
dat=data.frame(one=seq(1,15,by=14/n),
two=sample(seq(4,40,by=40/n),size = n,replace = F),
three=runif(n,min=1,max=20))
dat=data.frame(one=seq(1,15,by=14/n),
two=sample(seq(4,40,by=36/n),size = n,replace = F),
three=runif(n,min=1,max=20))
seq(1,15,by=14/n)
n
seq(1,15,by=14/(n-1))
dat=data.frame(one=seq(1,15,by=14/(n-1)),
two=sample(seq(4,40,by=36/n),size = n,replace = F),
three=runif(n,min=1,max=20))
dat
n=ceiling(runif(1,min=7,max=30))
dat=data.frame(one=seq(1,15,by=14/(n-1)),
two=sample(seq(4,40,by=36/n),size = n,replace = F),
three=runif(n,min=1,max=20))
dat
dim(dat)
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
shiny::runApp('C:/Users/J Miller/Desktop/Data Science Course/Data Products/Data Products Week 4 (Project)/Part 1 - Shiny')
